{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30195fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (284807, 31)\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Missing values:\n",
      " False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE   # to handle class imbalance\n",
    "\n",
    "# 1Ô∏è‚É£ Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\anasg\\\\OneDrive\\\\Desktop\\\\abdul raheem\\\\DataScience\\\\task3\\\\creditcard.csv\")   # replace with your dataset path\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# 2Ô∏è‚É£ Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum().any())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07df3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3Ô∏è‚É£ Feature scaling (normalize 'Amount' column)\n",
    "scaler = StandardScaler()\n",
    "df['NormalizedAmount'] = scaler.fit_transform(df[['Amount']])\n",
    "df = df.drop(columns=['Amount', 'Time'])   # drop unnecessary columns\n",
    "\n",
    "# 4Ô∏è‚É£ Features (X) and Target (y)\n",
    "X = df.drop('Class', axis=1)   # Class ‚Üí 0 = genuine, 1 = fraud\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6764e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Class\n",
      "0    284315\n",
      "1    284315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5Ô∏è‚É£ Handle class imbalance using SMOTE\n",
    "print(\"Before SMOTE:\", y.value_counts())\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "print(\"After SMOTE:\", y_resampled.value_counts())\n",
    "\n",
    "# 6Ô∏è‚É£ Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19744490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 7Ô∏è‚É£ Train Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "# 8Ô∏è‚É£ Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ Evaluation function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\nüìå Results for {model_name}:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(y_test, y_pred_log, \"Logistic Regression\")\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "\n",
    "# üîü Plot confusion matrix for Random Forest\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Genuine\",\"Fraud\"], yticklabels=[\"Genuine\",\"Fraud\"])\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
